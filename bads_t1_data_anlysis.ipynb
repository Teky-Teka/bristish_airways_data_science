{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1_ Task One: review data insights\n",
    "\n",
    "This notebook includes some code to collect review data from the `SkyTrax` [https://www.airlinequality.com] website using `BeautifulSoup` package for web scrapping. The collected data are saved it into a local `.csv` to perform analysis.\n",
    "\n",
    "## -1.a/b- Data scrapping & cleaning\n",
    "\n",
    "For this task, we focus our analysis on reviews related to British Airways and the Airline itself.\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. \n",
    "Now, we use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/1/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/2/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/3/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/4/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/5/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/6/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/7/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/8/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/9/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/10/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/11/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/12/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/13/?sortby=post_date%3ADesc&pagesize=100\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "https://www.airlinequality.com/airline-reviews/british-airways/page/14/?sortby=post_date%3ADesc&pagesize=100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m para \u001b[39min\u001b[39;00m parsed_content\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext_content\u001b[39m\u001b[39m\"\u001b[39m}):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# clean this data to remove any unnecessary text from each of the rows.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# Delete \"✅ Trip Verified\" or \"Not Verified as it's not relevant for investigation.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# Begin all review after the \"|\" sequence, after strimming the spaces \" \".\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     review \u001b[39m=\u001b[39m para\u001b[39m.\u001b[39mget_text()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     reviews\u001b[39m.\u001b[39mappend(review[review\u001b[39m.\u001b[39;49mindex(\u001b[39m\"\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mlstrip())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tekyteka/code/Teky-Teka/bristish_airways_data_science/bads_t1_data_anlysis.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m   ---> \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(reviews)\u001b[39m}\u001b[39;00m\u001b[39m total reviews\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "bads_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 100\n",
    "# if you want to collect more data, try increasing the number of pages!\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# loop to collect 1000 reviews by iterating through the paginated pages\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{bads_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "    print(url)\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    # loop to extract the \"text_content\" HTML class data\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        # clean this data to remove any unnecessary text from each of the rows.\n",
    "        # Delete \"✅ Trip Verified\" or \"Not Verified as it's not relevant for investigation.\n",
    "        # Begin all review after the \"|\" sequence, after strimming the spaces \" \".\n",
    "        review = para.get_text()\n",
    "        reviews.append(review[review.index(\"|\")+1:].lstrip())\n",
    "\n",
    "    print(f\"   ---> {len(reviews)} total reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extremely rude ground service. We were non-rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My son and I flew to Geneva last Sunday for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the price paid (bought during a sale) it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flight left on time and arrived over half an h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very Poor Business class product, BA is not ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Extremely rude ground service. We were non-rev...\n",
       "1  My son and I flew to Geneva last Sunday for a ...\n",
       "2  For the price paid (bought during a sale) it w...\n",
       "3  Flight left on time and arrived over half an h...\n",
       "4  Very Poor Business class product, BA is not ev..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to DataFrame format\n",
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store DataFrame to CSV format\n",
    "df.to_csv(\"data/BADS_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now we have our dataset for this task! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1.b- Data analysing\n",
    "### -1.b.1- Sentiment analysis - Word embedding\n",
    "For this task, we focus our data analysing on Natural Language Processing (NLP)  with sentiment analysing.\n",
    "As working on words directly is not possible we need to realize a word embedding.\n",
    "First we have to vextorize words to provide a mapping from the dictionary of words to vectors of a fixed dimension.\n",
    "For this task, we use `Python` and `word2vec` library to vectorize review words.\n",
    "\n",
    "# Keras Embedding\n",
    "Thanks to the `Embedding` layer in `Keras` library to feed a Recurrent Neural Network with vectorized text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirement\n",
    "\n",
    "Install [TensorFlow Datasets](https://www.tensorflow.org/datasets):\n",
    "\n",
    "```bash\n",
    "pip install tensorflow-datasets\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "### load the data ###\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "\n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "\n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "\n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "\n",
    "    # Decode each word in UTF-8\n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght of datasets\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ex. of sentences X => y:\n",
    "[[ f'X_train[{i}][{X_train[i][j]}] => y_train = {y_train[i]}' for j in range(len(X_train[i])//30)] for i in range(555, 560)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
